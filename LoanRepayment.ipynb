{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.externals import joblib \n",
    "import seaborn as sns\n",
    "#import ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle # to shuffle the data \n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "from subprocess import check_output\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 25 variables:\n",
    "\n",
    "ID: ID of each client\n",
    "LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
    "SEX: Gender (1=male, 2=female)\n",
    "EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "AGE: Age in years\n",
    "PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
    "PAY_2: Repayment status in August, 2005 (scale same as above)\n",
    "PAY_3: Repayment status in July, 2005 (scale same as above)\n",
    "PAY_4: Repayment status in June, 2005 (scale same as above)\n",
    "PAY_5: Repayment status in May, 2005 (scale same as above)\n",
    "PAY_6: Repayment status in April, 2005 (scale same as above)\n",
    "BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
    "BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
    "BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
    "BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
    "BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
    "BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
    "PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
    "PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
    "PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
    "PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
    "PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
    "PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
    "default.payment.next.month: Default payment (1=yes, 0=no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"UCI_Credit_Card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [ 'LIMIT_BAL','AGE','BILL_AMT1', 'BILL_AMT2','BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default_pay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'default.payment.next.month': 'default_pay', 'PAY_0': 'PAY_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default_pay  \n",
       "0       0.0       0.0       0.0            1  \n",
       "1    1000.0       0.0    2000.0            1  \n",
       "2    1000.0    1000.0    5000.0            0  \n",
       "3    1100.0    1069.0    1000.0            0  \n",
       "4    9000.0     689.0     679.0            0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "# default_pay (1=yes, 0=No)\n",
    "# gender (1=male, 2=female)\n",
    "# MARRIAGE (1=married, 2=single, 3=others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDUCATION has categories 5, 6 and 0 that are unlabelled.\n",
    "MARRIAGE has a label 0 that is undocumented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['EDUCATION'].replace(0, 4,inplace=True)\n",
    "data['EDUCATION'].replace(5, 4,inplace=True)\n",
    "data['EDUCATION'].replace(6, 4,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    14030\n",
       "1    10585\n",
       "3     4917\n",
       "4      468\n",
       "Name: EDUCATION, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.EDUCATION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for payment we are now using (0=pay duly, 1 = delay for one month, 2 = delay for two months etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAY_1'].replace(-1, 0,inplace=True)\n",
    "data['PAY_1'].replace(-2, 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAY_2'].replace(-1, 0,inplace=True)\n",
    "data['PAY_2'].replace(-2, 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAY_3'].replace(-1, 0,inplace=True)\n",
    "data['PAY_3'].replace(-2, 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAY_4'].replace(-1, 0,inplace=True)\n",
    "data['PAY_4'].replace(-2, 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAY_5'].replace(-1, 0,inplace=True)\n",
    "data['PAY_5'].replace(-2, 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAY_6'].replace(-1, 0,inplace=True)\n",
    "data['PAY_6'].replace(-2, 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing '0' to '3' for marriage (1=married, 2=single, 3=others)\n",
    "data['MARRIAGE'].replace(0, 3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX  default_pay\n",
       "1    0               9015\n",
       "     1               2873\n",
       "2    0              14349\n",
       "     1               3763\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['SEX', 'default_pay']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace all negative values with nan in dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['BILL_AMT1'] < 0), 'BILL_AMT1']=np.nan\n",
    "data.loc[(data['BILL_AMT2'] < 0), 'BILL_AMT2']=np.nan\n",
    "data.loc[(data['BILL_AMT3'] < 0), 'BILL_AMT3']=np.nan\n",
    "data.loc[(data['BILL_AMT4'] < 0), 'BILL_AMT4']=np.nan\n",
    "data.loc[(data['BILL_AMT5'] < 0), 'BILL_AMT5']=np.nan\n",
    "data.loc[(data['BILL_AMT6'] < 0), 'BILL_AMT6']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.get_loc(\"BILL_AMT6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BILL_AMT1    590\n",
       "BILL_AMT2    669\n",
       "BILL_AMT3    655\n",
       "BILL_AMT4    675\n",
       "BILL_AMT5    655\n",
       "BILL_AMT6    688\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,12:18 ].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29990</td>\n",
       "      <td>29991</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138325.0</td>\n",
       "      <td>137142.0</td>\n",
       "      <td>139110.0</td>\n",
       "      <td>138262.0</td>\n",
       "      <td>49675.0</td>\n",
       "      <td>46121.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>4228.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29991</td>\n",
       "      <td>29992</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29992</td>\n",
       "      <td>29993</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8802.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29993</td>\n",
       "      <td>29994</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>102996.0</td>\n",
       "      <td>70626.0</td>\n",
       "      <td>69473.0</td>\n",
       "      <td>55004.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>111784.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29994</td>\n",
       "      <td>29995</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>72557.0</td>\n",
       "      <td>77708.0</td>\n",
       "      <td>79384.0</td>\n",
       "      <td>77519.0</td>\n",
       "      <td>82607.0</td>\n",
       "      <td>81158.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29995</td>\n",
       "      <td>29996</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188948.0</td>\n",
       "      <td>192815.0</td>\n",
       "      <td>208365.0</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29996</td>\n",
       "      <td>29997</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29997</td>\n",
       "      <td>29998</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>3356.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29998</td>\n",
       "      <td>29999</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78379.0</td>\n",
       "      <td>76304.0</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29999</td>\n",
       "      <td>30000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47929.0</td>\n",
       "      <td>48905.0</td>\n",
       "      <td>49764.0</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  \\\n",
       "29990  29991   140000.0    1          2         1   41      0      0      0   \n",
       "29991  29992   210000.0    1          2         1   34      3      2      2   \n",
       "29992  29993    10000.0    1          3         1   43      0      0      0   \n",
       "29993  29994   100000.0    1          1         2   38      0      0      0   \n",
       "29994  29995    80000.0    1          2         2   34      2      2      2   \n",
       "29995  29996   220000.0    1          3         1   39      0      0      0   \n",
       "29996  29997   150000.0    1          3         2   43      0      0      0   \n",
       "29997  29998    30000.0    1          2         2   37      4      3      2   \n",
       "29998  29999    80000.0    1          3         1   41      1      0      0   \n",
       "29999  30000    50000.0    1          2         1   46      0      0      0   \n",
       "\n",
       "       PAY_4  PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  \\\n",
       "29990      0      0      0   138325.0   137142.0   139110.0   138262.0   \n",
       "29991      2      2      2     2500.0     2500.0     2500.0     2500.0   \n",
       "29992      0      0      0     8802.0    10400.0        0.0        0.0   \n",
       "29993      0      0      0     3042.0     1427.0   102996.0    70626.0   \n",
       "29994      2      2      2    72557.0    77708.0    79384.0    77519.0   \n",
       "29995      0      0      0   188948.0   192815.0   208365.0    88004.0   \n",
       "29996      0      0      0     1683.0     1828.0     3502.0     8979.0   \n",
       "29997      0      0      0     3565.0     3356.0     2758.0    20878.0   \n",
       "29998      0      0      0        NaN    78379.0    76304.0    52774.0   \n",
       "29999      0      0      0    47929.0    48905.0    49764.0    36535.0   \n",
       "\n",
       "       BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  \\\n",
       "29990    49675.0    46121.0    6000.0    7000.0    4228.0    1505.0    2000.0   \n",
       "29991     2500.0     2500.0       0.0       0.0       0.0       0.0       0.0   \n",
       "29992        0.0        0.0    2000.0       0.0       0.0       0.0       0.0   \n",
       "29993    69473.0    55004.0    2000.0  111784.0    4000.0    3000.0    2000.0   \n",
       "29994    82607.0    81158.0    7000.0    3500.0       0.0    7000.0       0.0   \n",
       "29995    31237.0    15980.0    8500.0   20000.0    5003.0    3047.0    5000.0   \n",
       "29996     5190.0        0.0    1837.0    3526.0    8998.0     129.0       0.0   \n",
       "29997    20582.0    19357.0       0.0       0.0   22000.0    4200.0    2000.0   \n",
       "29998    11855.0    48944.0   85900.0    3409.0    1178.0    1926.0   52964.0   \n",
       "29999    32428.0    15313.0    2078.0    1800.0    1430.0    1000.0    1000.0   \n",
       "\n",
       "       PAY_AMT6  default_pay  \n",
       "29990    2000.0            0  \n",
       "29991       0.0            1  \n",
       "29992       0.0            0  \n",
       "29993    2000.0            0  \n",
       "29994    4000.0            1  \n",
       "29995    1000.0            0  \n",
       "29996       0.0            0  \n",
       "29997    3100.0            1  \n",
       "29998    1804.0            1  \n",
       "29999    1000.0            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To view all columns\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "display(data.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing the nan values using imputation method\n",
    "There are clients that paid more then they were asked to, had even a negative bill in Sept., and still have a month of delay, and even defaulted the next month, so i am going to convert all the negative values into nan's and will replace them with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64400.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['BILL_AMT1'].loc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "data['BILL_AMT1'].loc[5] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will fill the 5th location with mean/median and use the method which gives the closest result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52273.68686456527"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['BILL_AMT1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23790.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['BILL_AMT1'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mean is closer to actual result so using the mean to fill the nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BILL_AMT1'] = data['BILL_AMT1'].fillna(data['BILL_AMT1'].mean())\n",
    "data['BILL_AMT2'] = data['BILL_AMT2'].fillna(data['BILL_AMT2'].mean())\n",
    "data['BILL_AMT3'] = data['BILL_AMT3'].fillna(data['BILL_AMT3'].mean())\n",
    "data['BILL_AMT4'] = data['BILL_AMT4'].fillna(data['BILL_AMT4'].mean())\n",
    "data['BILL_AMT5'] = data['BILL_AMT5'].fillna(data['BILL_AMT5'].mean())\n",
    "data['BILL_AMT6'] = data['BILL_AMT6'].fillna(data['BILL_AMT6'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BILL_AMT1    0\n",
       "BILL_AMT2    0\n",
       "BILL_AMT3    0\n",
       "BILL_AMT4    0\n",
       "BILL_AMT5    0\n",
       "BILL_AMT6    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,12:18 ].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing the missing values with KNN imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is the second method used for comapring the null value replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #using for loop to replace the negative values with nan\n",
    "# for i in tqdm(range (12, 18)):\n",
    "#     data2.iloc[:,i] = data2.iloc[:,i].replace((data2.iloc[:,i] < 0), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.loc[(data2['BILL_AMT1'] < 0), 'BILL_AMT1']=np.nan\n",
    "data2.loc[(data2['BILL_AMT2'] < 0), 'BILL_AMT2']=np.nan\n",
    "data2.loc[(data2['BILL_AMT3'] < 0), 'BILL_AMT3']=np.nan\n",
    "data2.loc[(data2['BILL_AMT4'] < 0), 'BILL_AMT4']=np.nan\n",
    "data2.loc[(data2['BILL_AMT5'] < 0), 'BILL_AMT5']=np.nan\n",
    "data2.loc[(data2['BILL_AMT6'] < 0), 'BILL_AMT6']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BILL_AMT1    590\n",
       "BILL_AMT2    669\n",
       "BILL_AMT3    655\n",
       "BILL_AMT4    675\n",
       "BILL_AMT5    655\n",
       "BILL_AMT6    688\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.iloc[:,12:18].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAY_AMT1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.columns[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the missing values with KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "data2['BILL_AMT1']= imputer.fit_transform(data2[['BILL_AMT1']])\n",
    "data2['BILL_AMT2']= imputer.fit_transform(data2[['BILL_AMT2']])\n",
    "data2['BILL_AMT3']= imputer.fit_transform(data2[['BILL_AMT3']])\n",
    "data2['BILL_AMT4']= imputer.fit_transform(data2[['BILL_AMT4']])\n",
    "data2['BILL_AMT5']= imputer.fit_transform(data2[['BILL_AMT5']])\n",
    "data2['BILL_AMT6']= imputer.fit_transform(data2[['BILL_AMT6']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29995</td>\n",
       "      <td>29996</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29996</td>\n",
       "      <td>29997</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29997</td>\n",
       "      <td>29998</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29998</td>\n",
       "      <td>29999</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29999</td>\n",
       "      <td>30000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  \\\n",
       "0          1    20000.0    2          2         1   24      2      2      0   \n",
       "1          2   120000.0    2          2         2   26      0      2      0   \n",
       "2          3    90000.0    2          2         2   34      0      0      0   \n",
       "3          4    50000.0    2          2         1   37      0      0      0   \n",
       "4          5    50000.0    1          2         1   57      0      0      0   \n",
       "...      ...        ...  ...        ...       ...  ...    ...    ...    ...   \n",
       "29995  29996   220000.0    1          3         1   39      0      0      0   \n",
       "29996  29997   150000.0    1          3         2   43      0      0      0   \n",
       "29997  29998    30000.0    1          2         2   37      4      3      2   \n",
       "29998  29999    80000.0    1          3         1   41      1      0      0   \n",
       "29999  30000    50000.0    1          2         1   46      0      0      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0          0  ...        0.0        0.0        0.0       0.0     689.0   \n",
       "1          0  ...     3272.0     3455.0     3261.0       0.0    1000.0   \n",
       "2          0  ...    14331.0    14948.0    15549.0    1518.0    1500.0   \n",
       "3          0  ...    28314.0    28959.0    29547.0    2000.0    2019.0   \n",
       "4          0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29995      0  ...    88004.0    31237.0    15980.0    8500.0   20000.0   \n",
       "29996      0  ...     8979.0     5190.0        0.0    1837.0    3526.0   \n",
       "29997      0  ...    20878.0    20582.0    19357.0       0.0       0.0   \n",
       "29998      0  ...    52774.0    11855.0    48944.0   85900.0    3409.0   \n",
       "29999      0  ...    36535.0    32428.0    15313.0    2078.0    1800.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default_pay  \n",
       "0           0.0       0.0       0.0       0.0            1  \n",
       "1        1000.0    1000.0       0.0    2000.0            1  \n",
       "2        1000.0    1000.0    1000.0    5000.0            0  \n",
       "3        1200.0    1100.0    1069.0    1000.0            0  \n",
       "4       10000.0    9000.0     689.0     679.0            0  \n",
       "...         ...       ...       ...       ...          ...  \n",
       "29995    5003.0    3047.0    5000.0    1000.0            0  \n",
       "29996    8998.0     129.0       0.0       0.0            0  \n",
       "29997   22000.0    4200.0    2000.0    3100.0            1  \n",
       "29998    1178.0    1926.0   52964.0    1804.0            1  \n",
       "29999    1430.0    1000.0    1000.0    1000.0            1  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BILL_AMT1    0\n",
       "BILL_AMT2    0\n",
       "BILL_AMT3    0\n",
       "BILL_AMT4    0\n",
       "BILL_AMT5    0\n",
       "BILL_AMT6    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.iloc[:,12:18].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data2['BILL_AMT1'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lis:\n",
    "    data2.loc[:,i] = data2.loc[:,i].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.7 ms, sys: 4.25 ms, total: 70.9 ms\n",
      "Wall time: 77.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1a1f7e0e90>,\n",
       "  <matplotlib.lines.Line2D at 0x1a1f7c5f90>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1a1f7f0950>,\n",
       "  <matplotlib.lines.Line2D at 0x1a1f7f0e50>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1a1f7e0250>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1a1f7e0f50>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1a1f7f78d0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline \n",
    "plt.boxplot(data2['BILL_AMT1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.1 ms, sys: 4.72 ms, total: 60.9 ms\n",
      "Wall time: 63.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1a1f5dbc10>,\n",
       "  <matplotlib.lines.Line2D at 0x1a1f5cef50>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1a1f5e0710>,\n",
       "  <matplotlib.lines.Line2D at 0x1a1f5e0c10>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1a1f5cef10>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1a1f5dbcd0>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1a1f5e8690>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline \n",
    "plt.boxplot(data2['AGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing the outliers with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = []\n",
    "# for i in lis:\n",
    "#     Q1 = data2[i].quantile(0.25)\n",
    "#     Q3 = data2[i].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     min = Q1 - (IQR*1.5)\n",
    "#     max = Q3 + (IQR*1.5)\n",
    "#     data2.loc[data2[i]<min1, ] =np.nan\n",
    "#     data2.loc[data2['LIMIT_BAL']>max1, 'LIMIT_BAL'] =np.nan\n",
    "# #     fil = ((data2[i] < min) & (data2[i] > max))\n",
    "# #     dataset.append(fil)\n",
    "# #     #data2[i][fil] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIMIT_BAL\n",
      "167\n",
      "AGE\n",
      "272\n",
      "BILL_AMT1\n",
      "2430\n",
      "BILL_AMT2\n",
      "2426\n",
      "BILL_AMT3\n",
      "2504\n",
      "BILL_AMT4\n",
      "2670\n",
      "BILL_AMT5\n",
      "2766\n",
      "BILL_AMT6\n",
      "2727\n",
      "PAY_AMT1\n",
      "2745\n",
      "PAY_AMT2\n",
      "2714\n",
      "PAY_AMT3\n",
      "2598\n",
      "PAY_AMT4\n",
      "2994\n",
      "PAY_AMT5\n",
      "2945\n",
      "PAY_AMT6\n",
      "2958\n",
      "default_pay\n",
      "6636\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "for i in lis:\n",
    "    Q1 = data2[i].quantile(0.25)\n",
    "    Q3 = data2[i].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    min1 = Q1 - (IQR*1.5)\n",
    "    max1 = Q3 + (IQR*1.5)\n",
    "    values.append((min1, max1))\n",
    "    print(i) \n",
    "    print(((data2[i] < (Q1 - 1.5 * IQR)) | (data2[i] > (Q3 + 1.5 * IQR))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-235000.0, 525000.0),\n",
       " (8.5, 60.5),\n",
       " (-89447.75, 161014.25),\n",
       " (-86009.375, 154015.625),\n",
       " (-81154.0, 144956.0),\n",
       " (-73944.0, 131576.0),\n",
       " (-69196.375, 121822.625),\n",
       " (-69219.875, 120249.125),\n",
       " (-5009.0, 11015.0),\n",
       " (-5417.5, 11250.5),\n",
       " (-5782.5, 10677.5),\n",
       " (-5279.875, 9589.125),\n",
       " (-5416.0, 9700.0),\n",
       " (-5705.625, 9823.375),\n",
       " (0.0, 0.0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29995</td>\n",
       "      <td>29996</td>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29996</td>\n",
       "      <td>29997</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29997</td>\n",
       "      <td>29998</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29998</td>\n",
       "      <td>29999</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29999</td>\n",
       "      <td>30000</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID LIMIT_BAL  SEX  EDUCATION  MARRIAGE AGE  PAY_1  PAY_2  PAY_3  \\\n",
       "0          1     20000    2          2         1  24      2      2      0   \n",
       "1          2    120000    2          2         2  26      0      2      0   \n",
       "2          3     90000    2          2         2  34      0      0      0   \n",
       "3          4     50000    2          2         1  37      0      0      0   \n",
       "4          5     50000    1          2         1  57      0      0      0   \n",
       "...      ...       ...  ...        ...       ...  ..    ...    ...    ...   \n",
       "29995  29996    220000    1          3         1  39      0      0      0   \n",
       "29996  29997    150000    1          3         2  43      0      0      0   \n",
       "29997  29998     30000    1          2         2  37      4      3      2   \n",
       "29998  29999     80000    1          3         1  41      1      0      0   \n",
       "29999  30000     50000    1          2         1  46      0      0      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3  \\\n",
       "0          0  ...          0          0         0        0      689        0   \n",
       "1          0  ...       3272       3455      3261        0     1000     1000   \n",
       "2          0  ...      14331      14948     15549     1518     1500     1000   \n",
       "3          0  ...      28314      28959     29547     2000     2019     1200   \n",
       "4          0  ...      20940      19146     19131     2000    36681    10000   \n",
       "...      ...  ...        ...        ...       ...      ...      ...      ...   \n",
       "29995      0  ...      88004      31237     15980     8500    20000     5003   \n",
       "29996      0  ...       8979       5190         0     1837     3526     8998   \n",
       "29997      0  ...      20878      20582     19357        0        0    22000   \n",
       "29998      0  ...      52774      11855     48944    85900     3409     1178   \n",
       "29999      0  ...      36535      32428     15313     2078     1800     1430   \n",
       "\n",
       "      PAY_AMT4 PAY_AMT5 PAY_AMT6 default_pay  \n",
       "0            0        0        0           1  \n",
       "1         1000        0     2000           1  \n",
       "2         1000     1000     5000           0  \n",
       "3         1100     1069     1000           0  \n",
       "4         9000      689      679           0  \n",
       "...        ...      ...      ...         ...  \n",
       "29995     3047     5000     1000           0  \n",
       "29996      129        0        0           0  \n",
       "29997     4200     2000     3100           1  \n",
       "29998     1926    52964     1804           1  \n",
       "29999     1000     1000     1000           1  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = pd.DataFrame(values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_list = pd.DataFrame(values, columns = ['min1' , 'max1']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min1    float64\n",
       "max1    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_list.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min1</th>\n",
       "      <th>max1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-235000.000</td>\n",
       "      <td>525000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.500</td>\n",
       "      <td>60.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-91739.625</td>\n",
       "      <td>162389.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-88547.500</td>\n",
       "      <td>155538.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-83581.500</td>\n",
       "      <td>146412.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-75942.125</td>\n",
       "      <td>132774.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-70878.250</td>\n",
       "      <td>122831.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-70657.375</td>\n",
       "      <td>121111.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-5009.000</td>\n",
       "      <td>11015.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-5417.500</td>\n",
       "      <td>11250.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-5782.500</td>\n",
       "      <td>10677.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>-5279.875</td>\n",
       "      <td>9589.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>-5416.000</td>\n",
       "      <td>9700.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>-5705.625</td>\n",
       "      <td>9823.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          min1        max1\n",
       "0  -235000.000  525000.000\n",
       "1        8.500      60.500\n",
       "2   -91739.625  162389.375\n",
       "3   -88547.500  155538.500\n",
       "4   -83581.500  146412.500\n",
       "5   -75942.125  132774.875\n",
       "6   -70878.250  122831.750\n",
       "7   -70657.375  121111.625\n",
       "8    -5009.000   11015.000\n",
       "9    -5417.500   11250.500\n",
       "10   -5782.500   10677.500\n",
       "11   -5279.875    9589.125\n",
       "12   -5416.000    9700.000\n",
       "13   -5705.625    9823.375\n",
       "14       0.000       0.000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['LIMIT_BAL'].quantile(0.25)\n",
    "Q3 = data2['LIMIT_BAL'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['LIMIT_BAL']<min1, 'LIMIT_BAL'] =np.nan\n",
    "data2.loc[data2['LIMIT_BAL']>max1, 'LIMIT_BAL'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['AGE'].quantile(0.25)\n",
    "Q3 = data2['AGE'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['AGE']<min1, 'AGE'] =np.nan\n",
    "data2.loc[data2['AGE']>max1, 'AGE'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['BILL_AMT1'].quantile(0.25)\n",
    "Q3 = data2['BILL_AMT1'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['BILL_AMT1']<min1, 'BILL_AMT1'] =np.nan\n",
    "data2.loc[data2['BILL_AMT1']>max1, 'BILL_AMT1'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['BILL_AMT2'].quantile(0.25)\n",
    "Q3 = data2['BILL_AMT2'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['BILL_AMT2']<min1, 'BILL_AMT2'] =np.nan\n",
    "data2.loc[data2['BILL_AMT2']>max1, 'BILL_AMT2'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['BILL_AMT3'].quantile(0.25)\n",
    "Q3 = data2['BILL_AMT3'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['BILL_AMT3']<min1, 'BILL_AMT3'] =np.nan\n",
    "data2.loc[data2['BILL_AMT3']>max1, 'BILL_AMT3'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['BILL_AMT4'].quantile(0.25)\n",
    "Q3 = data2['BILL_AMT4'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['BILL_AMT4']<min1, 'BILL_AMT4'] =np.nan\n",
    "data2.loc[data2['BILL_AMT4']>max1, 'BILL_AMT4'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['BILL_AMT5'].quantile(0.25)\n",
    "Q3 = data2['BILL_AMT5'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['BILL_AMT5']<min1, 'BILL_AMT5'] =np.nan\n",
    "data2.loc[data2['BILL_AMT5']>max1, 'BILL_AMT5'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['BILL_AMT6'].quantile(0.25)\n",
    "Q3 = data2['BILL_AMT6'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['BILL_AMT6']<min1, 'BILL_AMT6'] =np.nan\n",
    "data2.loc[data2['BILL_AMT6']>max1, 'BILL_AMT6'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['PAY_AMT1'].quantile(0.25)\n",
    "Q3 = data2['PAY_AMT1'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['PAY_AMT1']<min1, 'PAY_AMT1'] =np.nan\n",
    "data2.loc[data2['PAY_AMT1']>max1, 'PAY_AMT1'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['PAY_AMT2'].quantile(0.25)\n",
    "Q3 = data2['PAY_AMT2'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['PAY_AMT2']<min1, 'PAY_AMT2'] =np.nan\n",
    "data2.loc[data2['PAY_AMT2']>max1, 'PAY_AMT2'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['PAY_AMT3'].quantile(0.25)\n",
    "Q3 = data2['PAY_AMT3'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['PAY_AMT3']<min1, 'PAY_AMT3'] =np.nan\n",
    "data2.loc[data2['PAY_AMT3']>max1, 'PAY_AMT3'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['PAY_AMT4'].quantile(0.25)\n",
    "Q3 = data2['PAY_AMT4'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['PAY_AMT4']<min1, 'PAY_AMT4'] =np.nan\n",
    "data2.loc[data2['PAY_AMT4']>max1, 'PAY_AMT4'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['PAY_AMT5'].quantile(0.25)\n",
    "Q3 = data2['PAY_AMT5'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['PAY_AMT5']<min1, 'PAY_AMT5'] =np.nan\n",
    "data2.loc[data2['PAY_AMT5']>max1, 'PAY_AMT5'] =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data2['PAY_AMT6'].quantile(0.25)\n",
    "Q3 = data2['PAY_AMT6'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min1 = Q1 - (IQR*1.5)\n",
    "max1 = Q3 + (IQR*1.5)\n",
    "data2.loc[data2['PAY_AMT6']<min1, 'PAY_AMT6'] =np.nan\n",
    "data2.loc[data2['PAY_AMT6']>max1, 'PAY_AMT6'] =np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we didn't replce the outliers with means directly as the outliers will affect the mean. Now replacing the null values with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BILL_AMT1    2430\n",
       "BILL_AMT2    2426\n",
       "BILL_AMT3    2504\n",
       "BILL_AMT4    2670\n",
       "BILL_AMT5    2766\n",
       "BILL_AMT6    2727\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.iloc[:,12:18 ].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['LIMIT_BAL'] = data2['LIMIT_BAL'].fillna(data2['LIMIT_BAL'].mean())\n",
    "data2['AGE'] = data2['AGE'].fillna(data2['AGE'].mean())\n",
    "data2['BILL_AMT1'] = data2['BILL_AMT1'].fillna(data2['BILL_AMT1'].mean())\n",
    "data2['BILL_AMT2'] = data2['BILL_AMT2'].fillna(data2['BILL_AMT2'].mean())\n",
    "data2['BILL_AMT3'] = data2['BILL_AMT3'].fillna(data2['BILL_AMT3'].mean())\n",
    "data2['BILL_AMT4'] = data2['BILL_AMT4'].fillna(data2['BILL_AMT4'].mean())\n",
    "data2['BILL_AMT5'] = data2['BILL_AMT5'].fillna(data2['BILL_AMT5'].mean())\n",
    "data2['BILL_AMT6'] = data2['BILL_AMT6'].fillna(data2['BILL_AMT6'].mean())\n",
    "\n",
    "data2['PAY_AMT1'] = data2['PAY_AMT1'].fillna(data2['PAY_AMT1'].mean())\n",
    "data2['PAY_AMT2'] = data2['PAY_AMT2'].fillna(data2['PAY_AMT2'].mean())\n",
    "data2['PAY_AMT3'] = data2['PAY_AMT3'].fillna(data2['PAY_AMT3'].mean())\n",
    "data2['PAY_AMT4'] = data2['PAY_AMT4'].fillna(data2['PAY_AMT4'].mean())\n",
    "data2['PAY_AMT5'] = data2['PAY_AMT5'].fillna(data2['PAY_AMT5'].mean())\n",
    "data2['PAY_AMT6'] = data2['PAY_AMT6'].fillna(data2['PAY_AMT6'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection (Correlation Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1',\n",
       "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
       "       'default_pay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def correlation_matrix(df):\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib import cm as cm\n",
    "\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    cmap = cm.get_cmap('jet', 30)\n",
    "    cax = ax1.imshow(df.corr(),interpolation=\"nearest\", cmap=cmap)\n",
    "    ax1.grid(True)\n",
    "    plt.title('Feature Correlation')\n",
    "    labels=['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1',\n",
    "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
    "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
    "       'default_pay']\n",
    "    ax1.set_yticklabels(labels)\n",
    "    ax1.set_xticklabels(labels)\n",
    "    #ax1.set_xticklabels(labels,fontsize=10)\n",
    "    #ax1.set_yticklabels(labels,fontsize=10)\n",
    "    # Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "    fig.colorbar(cax, ticks=[.70,.75,.8,.85,.90,.95,1])\n",
    "    plt.show()\n",
    "\n",
    "correlation_matrix(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1fcb2b90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = data2.corr() \n",
    "\n",
    "f, ax = plt.subplots(figsize =(15, 10)) \n",
    "sns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(Col1, Col2):\n",
    "    res = data2.groupby([Col1, Col2]).size().unstack()\n",
    "    res['perc'] = (res[res.columns[1]]/(res[res.columns[0]] + res[res.columns[1]]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>default_pay</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8549</td>\n",
       "      <td>2036</td>\n",
       "      <td>0.192348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10700</td>\n",
       "      <td>3330</td>\n",
       "      <td>0.237349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3680</td>\n",
       "      <td>1237</td>\n",
       "      <td>0.251576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>435</td>\n",
       "      <td>33</td>\n",
       "      <td>0.070513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "default_pay      0     1      perc\n",
       "EDUCATION                         \n",
       "1             8549  2036  0.192348\n",
       "2            10700  3330  0.237349\n",
       "3             3680  1237  0.251576\n",
       "4              435    33  0.070513"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation('EDUCATION', 'default_pay')\n",
    "#Higher the education lower is the probability of defaulting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>default_pay</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10453</td>\n",
       "      <td>3206</td>\n",
       "      <td>0.234717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12623</td>\n",
       "      <td>3341</td>\n",
       "      <td>0.209283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>288</td>\n",
       "      <td>89</td>\n",
       "      <td>0.236074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "default_pay      0     1      perc\n",
       "MARRIAGE                          \n",
       "1            10453  3206  0.234717\n",
       "2            12623  3341  0.209283\n",
       "3              288    89  0.236074"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation('MARRIAGE', 'default_pay')\n",
    "#married people and other are most likey gonna default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SEX</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4354</td>\n",
       "      <td>6231</td>\n",
       "      <td>0.588663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5374</td>\n",
       "      <td>8656</td>\n",
       "      <td>0.616964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1990</td>\n",
       "      <td>2927</td>\n",
       "      <td>0.595282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>298</td>\n",
       "      <td>0.636752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SEX           1     2      perc\n",
       "EDUCATION                      \n",
       "1          4354  6231  0.588663\n",
       "2          5374  8656  0.616964\n",
       "3          1990  2927  0.595282\n",
       "4           170   298  0.636752"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation('EDUCATION', 'SEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>default_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24810</td>\n",
       "      <td>390.0</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25006</td>\n",
       "      <td>46868.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9892</td>\n",
       "      <td>140013.0</td>\n",
       "      <td>2739.524821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27823</td>\n",
       "      <td>79062.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>390.0</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17812</td>\n",
       "      <td>6571.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19091</td>\n",
       "      <td>42816.0</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25312</td>\n",
       "      <td>100190.0</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25652</td>\n",
       "      <td>17770.0</td>\n",
       "      <td>1558.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5075</td>\n",
       "      <td>21187.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BILL_AMT2     PAY_AMT1 default_pay\n",
       "24810      390.0   390.000000           1\n",
       "25006    46868.0     0.000000           1\n",
       "9892    140013.0  2739.524821           1\n",
       "27823    79062.0    15.000000           1\n",
       "2530       390.0   390.000000           1\n",
       "17812     6571.0     0.000000           1\n",
       "19091    42816.0  4600.000000           1\n",
       "25312   100190.0  5000.000000           1\n",
       "25652    17770.0  1558.000000           1\n",
       "5075     21187.0     0.000000           1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[data2.default_pay == 1][['BILL_AMT2', 'PAY_AMT1', 'default_pay']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saw that men are most likely to default and also that married people are most likely to default. \n",
    "Thus why not combine them in a single variable given by the product of the two.\n",
    "as we can see high correlation between the two categories hence we are going to combime 'SEX' and 'MARRIAGE' and make a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>default_pay</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_mar</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3844</td>\n",
       "      <td>1346</td>\n",
       "      <td>0.259345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5068</td>\n",
       "      <td>1485</td>\n",
       "      <td>0.226614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>42</td>\n",
       "      <td>0.289655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6609</td>\n",
       "      <td>1860</td>\n",
       "      <td>0.219625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7555</td>\n",
       "      <td>1856</td>\n",
       "      <td>0.197216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>185</td>\n",
       "      <td>47</td>\n",
       "      <td>0.202586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "default_pay     0     1      perc\n",
       "gen_mar                          \n",
       "1            3844  1346  0.259345\n",
       "2            5068  1485  0.226614\n",
       "3             103    42  0.289655\n",
       "4            6609  1860  0.219625\n",
       "5            7555  1856  0.197216\n",
       "6             185    47  0.202586"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['gen_mar'] = 0\n",
    "data2.loc[((data2.SEX == 1) & (data2.MARRIAGE == 1)) , 'gen_mar'] = 1 #married man\n",
    "data2.loc[((data2.SEX == 1) & (data2.MARRIAGE == 2)) , 'gen_mar'] = 2 #single man\n",
    "data2.loc[((data2.SEX == 1) & (data2.MARRIAGE == 3)) , 'gen_mar'] = 3 #divorced man\n",
    "data2.loc[((data2.SEX == 2) & (data2.MARRIAGE == 1)) , 'gen_mar'] = 4 #married woman\n",
    "data2.loc[((data2.SEX == 2) & (data2.MARRIAGE == 2)) , 'gen_mar'] = 5 #single woman\n",
    "data2.loc[((data2.SEX == 2) & (data2.MARRIAGE == 3)) , 'gen_mar'] = 6 #divorced woman\n",
    "correlation('gen_mar', 'default_pay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Deleting columns 'SEX' and 'MARRIAGE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data2['SEX']\n",
    "del data2['MARRIAGE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making bin for various age groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Age_bin'] = pd.cut(data2.AGE, bins = 6, labels=[1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    9411\n",
       "4    8469\n",
       "2    6553\n",
       "1    5190\n",
       "6     232\n",
       "3     145\n",
       "Name: gen_mar, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.gen_mar.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'EDUCATION', 'AGE', 'PAY_1', 'PAY_2', 'PAY_3',\n",
       "       'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
       "       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',\n",
       "       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default_pay',\n",
       "       'gen_mar', 'Age_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 25)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(data2.columns)\n",
    "cols = cols[:-3] + [cols[-2]] + [cols[-1]] +[cols[-3]]\n",
    "data2 = data2[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data2['AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'EDUCATION', 'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4',\n",
       "       'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
       "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
       "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'gen_mar', 'Age_bin',\n",
       "       'default_pay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the final dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cleanedcreditcard_1.pkl']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # save data (without replacing -ve values + replacing outliers + feature selection) as pikel file \n",
    "# joblib.dump(data2, 'cleanedcreditcard_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the data(without replacing -ve values + replacing outliers + feature selection) clean data from the file \n",
    "# data2 = joblib.load('cleanedcreditcard_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cleanedcreditcard_2.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # save data (replacing -ve values + replacing outliers + feature selection) as pikel file \n",
    "# joblib.dump(data2, 'cleanedcreditcard_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data(without replacing -ve values + replacing outliers + feature selection) clean data from the file \n",
    "data2 = joblib.load('cleanedcreditcard_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'EDUCATION', 'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4',\n",
       "       'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
       "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
       "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'gen_mar', 'Age_bin',\n",
       "       'default_pay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data2.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2.iloc[:, 0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data2.iloc[:22500, :]\n",
    "df_test = data2.iloc[22500:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17412\n",
      "-----------\n",
      "5088\n",
      "-----------\n",
      "0    17412\n",
      "1     5088\n",
      "Name: default_pay, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_majority = df_train[df_train.default_pay==0]\n",
    "df_minority = df_train[df_train.default_pay==1]\n",
    "\n",
    "print(df_majority.default_pay.count())\n",
    "print(\"-----------\")\n",
    "print(df_minority.default_pay.count())\n",
    "print(\"-----------\")\n",
    "print(df_train.default_pay.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=17412,    # to match majority class\n",
    "                                 random_state=5) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17412\n",
       "0    17412\n",
       "Name: default_pay, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display new class counts\n",
    "df_upsampled.default_pay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34824, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default_pay'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_upsampled.iloc[:, 0:-1].values\n",
    "y = df_upsampled.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying various ML models to check the accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set(95%, 92% us)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_naive = GaussianNB()\n",
    "classifier_naive.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classifier_naive.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = classifier_naive.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5722490236618424\n",
      "Precision Score : 0.5587301587301587\n",
      "Recall Score : 0.6873420629450954\n",
      "F1 Score : 0.6163988463123198\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data(data = cleanedcreditcard_2)(upsampled)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_test)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_test)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6761333333333334\n",
      "Precision Score : 0.31805293005671076\n",
      "Recall Score : 0.405666063893912\n",
      "F1 Score : 0.3565562913907284\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data(data = cleanedcreditcard_2)( without sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_test)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_test)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5861474844934528\n",
      "Precision Score : 0.5705948795180723\n",
      "Recall Score : 0.6963014013324145\n",
      "F1 Score : 0.6272115882048629\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (-ve replaced)(data = cleanedcreditcard_2)(upsampled)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train)))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train)))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6901777777777778\n",
      "Precision Score : 0.33976213436194147\n",
      "Recall Score : 0.4247538677918425\n",
      "F1 Score : 0.3775337083668185\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (without -ve replace)(data = cleanedcreditcard_2)(without sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train)))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train)))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5736273834137376\n",
      "Precision Score : 0.5597836224584966\n",
      "Recall Score : 0.6894096025729382\n",
      "F1 Score : 0.6178711138562899\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data(data = cleanedcreditcard_1)(upsampled)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_test)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_test)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5861474844934528\n",
      "Precision Score : 0.5704622322435174\n",
      "Recall Score : 0.6974500344589938\n",
      "F1 Score : 0.6275968992248062\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (without -ve replace)(data = cleanedcreditcard_1)(upsampled)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train)))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train)))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 2992\n",
      "False Positive: 2363\n",
      "True Negative: 1990\n",
      "False Negative: 1361\n",
      "Precision: 0.56\n",
      "Recall: 0.69\n",
      "Problematic ratio: 0.31\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (without -ve replace)(data = cleanedcreditcard_1)(upsampled)\n",
    "TP = np.sum(np.logical_and(y_pred_test == 1, y_test == 1))\n",
    "TN = np.sum(np.logical_and(y_pred_test == 0, y_test == 0))\n",
    "FP = np.sum(np.logical_and(y_pred_test == 1, y_test == 0))\n",
    "FN = np.sum(np.logical_and(y_pred_test == 0, y_test == 1))\n",
    "pred = len(y_pred_test)\n",
    "\n",
    "print('True Positives: {}'.format(TP))\n",
    "print('False Positive: {}'.format(FP))\n",
    "print('True Negative: {}'.format(TN))\n",
    "print('False Negative: {}'.format(FN))\n",
    "print('Precision: {}'.format(round(TP/(TP+FP),2)))\n",
    "print('Recall: {}'.format(round(TP/(TP+FN),2)))\n",
    "print('Problematic ratio: {}'.format(round(FN/(FN+TP),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 676\n",
      "False Positive: 1441\n",
      "True Negative: 4400\n",
      "False Negative: 983\n",
      "Precision: 0.32\n",
      "Recall: 0.41\n",
      "Problematic ratio: 0.59\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (without -ve replace)(data = cleanedcreditcard_1)(upsampled)\n",
    "TP = np.sum(np.logical_and(y_pred_test == 1, y_test == 1))\n",
    "TN = np.sum(np.logical_and(y_pred_test == 0, y_test == 0))\n",
    "FP = np.sum(np.logical_and(y_pred_test == 1, y_test == 0))\n",
    "FN = np.sum(np.logical_and(y_pred_test == 0, y_test == 1))\n",
    "pred = len(y_pred_test)\n",
    "\n",
    "print('True Positives: {}'.format(TP))\n",
    "print('False Positive: {}'.format(FP))\n",
    "print('True Negative: {}'.format(TN))\n",
    "print('False Negative: {}'.format(FN))\n",
    "print('Precision: {}'.format(round(TP/(TP+FP),2)))\n",
    "print('Recall: {}'.format(round(TP/(TP+FN),2)))\n",
    "print('Problematic ratio: {}'.format(round(FN/(FN+TP),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 3001\n",
      "False Positive: 2360\n",
      "True Negative: 1993\n",
      "False Negative: 1352\n",
      "Precision: 0.56\n",
      "Recall: 0.69\n",
      "Problematic ratio: 0.31\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (without -ve replace)(data = cleanedcreditcard_1)\n",
    "TP = np.sum(np.logical_and(y_pred_test == 1, y_test == 1))\n",
    "TN = np.sum(np.logical_and(y_pred_test == 0, y_test == 0))\n",
    "FP = np.sum(np.logical_and(y_pred_test == 1, y_test == 0))\n",
    "FN = np.sum(np.logical_and(y_pred_test == 0, y_test == 1))\n",
    "pred = len(y_pred_test)\n",
    "\n",
    "print('True Positives: {}'.format(TP))\n",
    "print('False Positive: {}'.format(FP))\n",
    "print('True Negative: {}'.format(TN))\n",
    "print('False Negative: {}'.format(FN))\n",
    "print('Precision: {}'.format(round(TP/(TP+FP),2)))\n",
    "print('Recall: {}'.format(round(TP/(TP+FN),2)))\n",
    "print('Problematic ratio: {}'.format(round(FN/(FN+TP),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = y_pred_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = y_pred_train.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 159\n",
      "False Positive: 20\n",
      "True Negative: 4331\n",
      "False Negative: 4186\n",
      "Precision: 0.89\n",
      "Recall: 0.04\n",
      "Problematic ratio: 0.96\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data (-ve replaced)(data = cleanedcreditcard_2)\n",
    "TP = np.sum(np.logical_and(y_pred_test == 1, y_test == 1))\n",
    "TN = np.sum(np.logical_and(y_pred_test == 0, y_test == 0))\n",
    "FP = np.sum(np.logical_and(y_pred_test == 1, y_test == 0))\n",
    "FN = np.sum(np.logical_and(y_pred_test == 0, y_test == 1))\n",
    "pred = len(y_pred_test)\n",
    "\n",
    "print('True Positives: {}'.format(TP))\n",
    "print('False Positive: {}'.format(FP))\n",
    "print('True Negative: {}'.format(TN))\n",
    "print('False Negative: {}'.format(FN))\n",
    "print('Precision: {}'.format(round(TP/(TP+FP),2)))\n",
    "print('Recall: {}'.format(round(TP/(TP+FN),2)))\n",
    "print('Problematic ratio: {}'.format(round(FN/(FN+TP),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5157362738341373\n",
      "Precision Score : 0.5157362738341373\n",
      "Recall Score : 0.5157362738341373\n",
      "F1 Score : 0.5157362738341373\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data (-ve replaced)(data = cleanedcreditcard_2) (with sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_test, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_test, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_test, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7809333333333334\n",
      "Precision Score : 0.7809333333333334\n",
      "Recall Score : 0.7809333333333334\n",
      "F1 Score : 0.7809333333333334\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data (-ve replaced)(data = cleanedcreditcard_2) (without sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_test, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_test, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_test, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5176889501493223\n",
      "Precision Score : 0.5176889501493223\n",
      "Recall Score : 0.5176889501493223\n",
      "F1 Score : 0.5176889501493223\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (-ve replace)(data = cleanedcreditcard_2) (with sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7810222222222222\n",
      "Precision Score : 0.7810222222222222\n",
      "Recall Score : 0.7810222222222222\n",
      "F1 Score : 0.7810222222222221\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (-ve replace)(data = cleanedcreditcard_2) (without sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 156\n",
      "False Positive: 20\n",
      "True Negative: 4331\n",
      "False Negative: 4189\n",
      "Precision: 0.89\n",
      "Recall: 0.04\n",
      "Problematic ratio: 0.96\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data (without -ve replace)(data = cleanedcreditcard_1)\n",
    "TP = np.sum(np.logical_and(y_pred_test == 1, y_test == 1))\n",
    "TN = np.sum(np.logical_and(y_pred_test == 0, y_test == 0))\n",
    "FP = np.sum(np.logical_and(y_pred_test == 1, y_test == 0))\n",
    "FN = np.sum(np.logical_and(y_pred_test == 0, y_test == 1))\n",
    "pred = len(y_pred_test)\n",
    "\n",
    "print('True Positives: {}'.format(TP))\n",
    "print('False Positive: {}'.format(FP))\n",
    "print('True Negative: {}'.format(TN))\n",
    "print('False Negative: {}'.format(FN))\n",
    "print('Precision: {}'.format(round(TP/(TP+FP),2)))\n",
    "print('Recall: {}'.format(round(TP/(TP+FN),2)))\n",
    "print('Problematic ratio: {}'.format(round(FN/(FN+TP),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5153916838961635\n",
      "Precision Score : 0.5153916838961635\n",
      "Recall Score : 0.5153916838961635\n",
      "F1 Score : 0.5153916838961635\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data (without -ve replace)(data = cleanedcreditcard_1)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_test, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_test, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_test, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5173826479822344\n",
      "Precision Score : 0.5173826479822344\n",
      "Recall Score : 0.5173826479822344\n",
      "F1 Score : 0.5173826479822344\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (without -ve replace)(data = cleanedcreditcard_1)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.009, 0.01, 0.09, 1, 5, 10, 25],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search (cv)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf_grid = LogisticRegression()\n",
    "grid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
    "grid_clf_acc_cv = GridSearchCV(clf_grid, param_grid = grid_values, cv = 10)\n",
    "grid_clf_acc_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = grid_clf_acc_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = grid_clf_acc_cv.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5157362738341373\n",
      "Precision Score : 0.5157362738341373\n",
      "Recall Score : 0.5157362738341373\n",
      "F1 Score : 0.5157362738341373\n"
     ]
    }
   ],
   "source": [
    "# # New Model Evaluation metrics for test data (-ve replaced)(data = cleanedcreditcard_2)\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "# print('Precision Score : ' + str(precision_score(y_test,y_pred_test, average='micro')))\n",
    "# print('Recall Score : ' + str(recall_score(y_test,y_pred_test, average='micro')))\n",
    "# print('F1 Score : ' + str(f1_score(y_test,y_pred_test, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7809333333333334\n",
      "Precision Score : 0.7809333333333334\n",
      "Recall Score : 0.7809333333333334\n",
      "F1 Score : 0.7809333333333334\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data (-ve replaced)(data = cleanedcreditcard_2)(without sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_test, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_test, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_test, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5885213262883835\n",
      "Precision Score : 0.5885213262883835\n",
      "Recall Score : 0.5885213262883835\n",
      "F1 Score : 0.5885213262883835\n"
     ]
    }
   ],
   "source": [
    "# # New Model Evaluation metrics for train data (-ve replaced)(data = cleanedcreditcard_2)\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "# print('Precision Score : ' + str(precision_score(y_train,y_pred_train, average='micro')))\n",
    "# print('Recall Score : ' + str(recall_score(y_train,y_pred_train, average='micro')))\n",
    "# print('F1 Score : ' + str(f1_score(y_train,y_pred_train, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7789333333333334\n",
      "Precision Score : 0.7789333333333334\n",
      "Recall Score : 0.7789333333333334\n",
      "F1 Score : 0.7789333333333334\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (-ve replaced)(data = cleanedcreditcard_2) (without sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5153916838961635\n",
      "Precision Score : 0.5153916838961635\n",
      "Recall Score : 0.5153916838961635\n",
      "F1 Score : 0.5153916838961635\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for test data (without -ve replaced)(data = cleanedcreditcard_1)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_test, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_test, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_test, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5885596140592695\n",
      "Precision Score : 0.5885596140592695\n",
      "Recall Score : 0.5885596140592695\n",
      "F1 Score : 0.5885596140592695\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics for train data (data = cleanedcreditcard_1)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train, average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train, average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7809333333333334\n",
      "Precision Score : 0.7222222222222222\n",
      "Recall Score : 0.01567209162145871\n",
      "F1 Score : 0.030678466076696168\n"
     ]
    }
   ],
   "source": [
    "# # New Model Evaluation metrics for test data (without -ve replace)(data = cleanedcreditcard_2)\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_test)))\n",
    "# print('Precision Score : ' + str(precision_score(y_test,y_pred_test)))\n",
    "# print('Recall Score : ' + str(recall_score(y_test,y_pred_test)))\n",
    "# print('F1 Score : ' + str(f1_score(y_test,y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7786666666666666\n",
      "Precision Score : 0.2857142857142857\n",
      "Recall Score : 0.0004018485031143259\n",
      "F1 Score : 0.0008025682182985555\n"
     ]
    }
   ],
   "source": [
    "# # New Model Evaluation metrics for train data (without -ve replace)(data = cleanedcreditcard_2)\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "# print('Precision Score : ' + str(precision_score(y_train,y_pred_train)))\n",
    "# print('Recall Score : ' + str(recall_score(y_train,y_pred_train)))\n",
    "# print('F1 Score : ' + str(f1_score(y_train,y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 26\n",
      "False Positive: 10\n",
      "True Negative: 5831\n",
      "False Negative: 1633\n",
      "Precision: 0.72\n",
      "Recall: 0.02\n",
      "Problematic ratio: 0.98\n"
     ]
    }
   ],
   "source": [
    "# TP = np.sum(np.logical_and(y_pred_test == 1, y_test == 1))\n",
    "# TN = np.sum(np.logical_and(y_pred_test == 0, y_test == 0))\n",
    "# FP = np.sum(np.logical_and(y_pred_test == 1, y_test == 0))\n",
    "# FN = np.sum(np.logical_and(y_pred_test == 0, y_test == 1))\n",
    "# pred = len(y_pred_test)\n",
    "\n",
    "# print('True Positives: {}'.format(TP))\n",
    "# print('False Positive: {}'.format(FP))\n",
    "# print('True Negative: {}'.format(TN))\n",
    "# print('False Negative: {}'.format(FN))\n",
    "# print('Precision: {}'.format(round(TP/(TP+FP),2)))\n",
    "# print('Recall: {}'.format(round(TP/(TP+FN),2)))\n",
    "# print('Problematic ratio: {}'.format(round(FN/(FN+TP),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "import time \n",
    "from keras.models import Sequential #(used to initialise the nural network)\n",
    "from keras.layers import Dense #(used to create the layers in ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds#contains tokeniser  \n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 23)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu', input_dim = 23))\n",
    "    classifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [25, 32],\n",
    "              'epochs': [10],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Âµs, sys: 0 ns, total: 2 Âµs\n",
      "Wall time: 5.01 Âµs\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 75us/step - loss: 0.5416 - accuracy: 0.7737\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 75us/step - loss: 0.5124 - accuracy: 0.7802\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 3s 147us/step - loss: 0.5085 - accuracy: 0.7803\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 3s 147us/step - loss: 0.5078 - accuracy: 0.7803\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 118us/step - loss: 0.5078 - accuracy: 0.7803\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 3s 134us/step - loss: 0.5065 - accuracy: 0.7805\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 5s 253us/step - loss: 0.5059 - accuracy: 0.78051s\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 4s 176us/step - loss: 0.5071 - accuracy: 0.7798\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 3s 160us/step - loss: 0.5070 - accuracy: 0.78031s - loss:\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 2s 123us/step - loss: 0.5046 - accuracy: 0.7803\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 118us/step - loss: 0.9253 - accuracy: 0.7576\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 82us/step - loss: 0.5195 - accuracy: 0.7772\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 77us/step - loss: 0.5166 - accuracy: 0.7782\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 2s 80us/step - loss: 0.5140 - accuracy: 0.7784\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 89us/step - loss: 0.5129 - accuracy: 0.7784\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 81us/step - loss: 0.5124 - accuracy: 0.7783\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 2s 108us/step - loss: 0.5107 - accuracy: 0.7784\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 5s 246us/step - loss: 0.5122 - accuracy: 0.7784\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 5s 256us/step - loss: 0.5105 - accuracy: 0.77841s - loss: - ETA: 0s - loss:\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 4s 199us/step - loss: 0.5106 - accuracy: 0.7784\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 123us/step - loss: 0.5535 - accuracy: 0.7729\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 107us/step - loss: 0.5200 - accuracy: 0.7770\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 113us/step - loss: 0.5164 - accuracy: 0.7771\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 2s 100us/step - loss: 0.5154 - accuracy: 0.7772\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 110us/step - loss: 0.5135 - accuracy: 0.7771\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 105us/step - loss: 0.5117 - accuracy: 0.7775\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 2s 86us/step - loss: 0.5108 - accuracy: 0.7773\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 100us/step - loss: 0.5103 - accuracy: 0.7775\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 2s 88us/step - loss: 0.5102 - accuracy: 0.7773\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 3s 142us/step - loss: 0.5111 - accuracy: 0.7773\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 121us/step - loss: 0.5793 - accuracy: 0.7720\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 116us/step - loss: 0.5157 - accuracy: 0.7789\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 87us/step - loss: 0.5122 - accuracy: 0.7790\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 4s 174us/step - loss: 0.5106 - accuracy: 0.7788\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 5s 243us/step - loss: 0.5094 - accuracy: 0.7788\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 4s 216us/step - loss: 0.5091 - accuracy: 0.7790\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 2s 105us/step - loss: 0.5093 - accuracy: 0.7789\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 78us/step - loss: 0.5091 - accuracy: 0.7790\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 2s 91us/step - loss: 0.5091 - accuracy: 0.7790\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 2s 112us/step - loss: 0.5104 - accuracy: 0.7790\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 100us/step - loss: 0.5612 - accuracy: 0.7697\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 85us/step - loss: 0.5148 - accuracy: 0.7794\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 93us/step - loss: 0.5109 - accuracy: 0.7795\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 2s 87us/step - loss: 0.5087 - accuracy: 0.7795\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 92us/step - loss: 0.5093 - accuracy: 0.7794\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 3s 127us/step - loss: 0.5099 - accuracy: 0.7795\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 2s 90us/step - loss: 0.5083 - accuracy: 0.7795\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 94us/step - loss: 0.5084 - accuracy: 0.7795\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 2s 90us/step - loss: 0.5074 - accuracy: 0.7795\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 2s 101us/step - loss: 0.5086 - accuracy: 0.7795\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 92us/step - loss: 0.6632 - accuracy: 0.7692\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 82us/step - loss: 0.5133 - accuracy: 0.7799\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 82us/step - loss: 0.5123 - accuracy: 0.7797\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 2s 78us/step - loss: 0.5101 - accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 85us/step - loss: 0.5101 - accuracy: 0.7798\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 84us/step - loss: 0.5086 - accuracy: 0.7798\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 2s 85us/step - loss: 0.5089 - accuracy: 0.7795\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 80us/step - loss: 0.5075 - accuracy: 0.7799\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 2s 86us/step - loss: 0.5078 - accuracy: 0.7798\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 2s 78us/step - loss: 0.5075 - accuracy: 0.7799\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 88us/step - loss: 0.5504 - accuracy: 0.7697\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 85us/step - loss: 0.5164 - accuracy: 0.7770\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 85us/step - loss: 0.5139 - accuracy: 0.7771\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 2s 91us/step - loss: 0.5139 - accuracy: 0.7772\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 83us/step - loss: 0.5122 - accuracy: 0.7771\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 82us/step - loss: 0.5112 - accuracy: 0.7768\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 2s 81us/step - loss: 0.5107 - accuracy: 0.7767 0s - loss:\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 92us/step - loss: 0.5101 - accuracy: 0.7773\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 2s 82us/step - loss: 0.5098 - accuracy: 0.7780\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 2s 78us/step - loss: 0.5095 - accuracy: 0.7773\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 85us/step - loss: 0.5876 - accuracy: 0.7727\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 76us/step - loss: 0.5161 - accuracy: 0.7792\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 83us/step - loss: 0.5108 - accuracy: 0.7790\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 2s 75us/step - loss: 0.5085 - accuracy: 0.7791\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 79us/step - loss: 0.5083 - accuracy: 0.7791\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 82us/step - loss: 0.5077 - accuracy: 0.7791\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5073 - accuracy: 0.7790\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 61us/step - loss: 0.5069 - accuracy: 0.7795\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5074 - accuracy: 0.7800\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 61us/step - loss: 0.5082 - accuracy: 0.7800\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 65us/step - loss: 0.5715 - accuracy: 0.7715\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5181 - accuracy: 0.7777\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5165 - accuracy: 0.7776\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5157 - accuracy: 0.7779\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 58us/step - loss: 0.5145 - accuracy: 0.7779\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 78us/step - loss: 0.5102 - accuracy: 0.7779\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 58us/step - loss: 0.5101 - accuracy: 0.7779\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5111 - accuracy: 0.7779\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5114 - accuracy: 0.7778\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 57us/step - loss: 0.5099 - accuracy: 0.7777\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 68us/step - loss: 0.5492 - accuracy: 0.7734\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5176 - accuracy: 0.7791\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5109 - accuracy: 0.7795\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 58us/step - loss: 0.5096 - accuracy: 0.7795\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5097 - accuracy: 0.7796\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5095 - accuracy: 0.7795\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5076 - accuracy: 0.7795\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5073 - accuracy: 0.7795\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5093 - accuracy: 0.7795\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5065 - accuracy: 0.7796\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 61us/step - loss: 0.5714 - accuracy: 0.7701\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5175 - accuracy: 0.7803\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5176 - accuracy: 0.7801 0s - loss: 0.5203 - accuracy: 0.\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5127 - accuracy: 0.7801\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 55us/step - loss: 0.5137 - accuracy: 0.7801\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5103 - accuracy: 0.7803\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5113 - accuracy: 0.7802\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 56us/step - loss: 0.5116 - accuracy: 0.7802\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5095 - accuracy: 0.7802\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5116 - accuracy: 0.7800\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 61us/step - loss: 0.5912 - accuracy: 0.7647\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 56us/step - loss: 0.5219 - accuracy: 0.7783\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5172 - accuracy: 0.7784\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5166 - accuracy: 0.7784\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5151 - accuracy: 0.7784\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5167 - accuracy: 0.7784\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5153 - accuracy: 0.7784\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5155 - accuracy: 0.7784\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5144 - accuracy: 0.7784\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5156 - accuracy: 0.7784\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 58us/step - loss: 0.5707 - accuracy: 0.7658\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5206 - accuracy: 0.7769\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5168 - accuracy: 0.7774\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5176 - accuracy: 0.7770\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5168 - accuracy: 0.7773\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5192 - accuracy: 0.7774\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5164 - accuracy: 0.7773\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5181 - accuracy: 0.7774\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5201 - accuracy: 0.7773\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5182 - accuracy: 0.7774\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5358 - accuracy: 0.7753\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5172 - accuracy: 0.7790\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5186 - accuracy: 0.7790\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5168 - accuracy: 0.7790\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5163 - accuracy: 0.7785\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5150 - accuracy: 0.7790\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5161 - accuracy: 0.7790\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5148 - accuracy: 0.7789\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5126 - accuracy: 0.7790\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5166 - accuracy: 0.7789\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5609 - accuracy: 0.7702\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5181 - accuracy: 0.7794\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 55us/step - loss: 0.5206 - accuracy: 0.7795\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 56us/step - loss: 0.5165 - accuracy: 0.7795 0s - loss: 0.5141 - accuracy: \n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5178 - accuracy: 0.7795\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5164 - accuracy: 0.7795\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5185 - accuracy: 0.7795\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5186 - accuracy: 0.7795\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5186 - accuracy: 0.7795\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5165 - accuracy: 0.7795\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 57us/step - loss: 0.6021 - accuracy: 0.7671\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5172 - accuracy: 0.7798\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5154 - accuracy: 0.7798\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250/20250 [==============================] - 1s 71us/step - loss: 0.5150 - accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 61us/step - loss: 0.5141 - accuracy: 0.7797\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5113 - accuracy: 0.7799\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5123 - accuracy: 0.7799\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 63us/step - loss: 0.5134 - accuracy: 0.7798\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 61us/step - loss: 0.5132 - accuracy: 0.7799 0s - loss: 0.5142 - accuracy:  - ETA: 0s - loss: 0.516\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5158 - accuracy: 0.7799\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 71us/step - loss: 0.5662 - accuracy: 0.7697\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5196 - accuracy: 0.7770\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 64us/step - loss: 0.5192 - accuracy: 0.7772 0s - loss: 0.516 - ETA: 0s - loss: 0.5176 - accuracy: \n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 2s 80us/step - loss: 0.5174 - accuracy: 0.7772\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 85us/step - loss: 0.5192 - accuracy: 0.7772\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 74us/step - loss: 0.5172 - accuracy: 0.7772\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 4s 222us/step - loss: 0.5211 - accuracy: 0.7772\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 84us/step - loss: 0.5188 - accuracy: 0.7771\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 2s 103us/step - loss: 0.5193 - accuracy: 0.7772\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 2s 79us/step - loss: 0.5196 - accuracy: 0.7772\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 110us/step - loss: 0.5940 - accuracy: 0.7661\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 3s 124us/step - loss: 0.5180 - accuracy: 0.7791\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 96us/step - loss: 0.5190 - accuracy: 0.7785\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 66us/step - loss: 0.5176 - accuracy: 0.7791 \n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 94us/step - loss: 0.5173 - accuracy: 0.7790\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 99us/step - loss: 0.5180 - accuracy: 0.7791\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 2s 93us/step - loss: 0.5188 - accuracy: 0.7791\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 90us/step - loss: 0.5185 - accuracy: 0.7791\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 73us/step - loss: 0.5179 - accuracy: 0.7791\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 73us/step - loss: 0.5197 - accuracy: 0.7791\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 3s 132us/step - loss: 0.5579 - accuracy: 0.7704\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 77us/step - loss: 0.5246 - accuracy: 0.7779 1s - loss: 0.4992 - accura - ETA: 1s - loss: 0.5134  - ETA: 0s - loss: 0\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 79us/step - loss: 0.5206 - accuracy: 0.7778 0s - loss: 0.5188 - accu\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 63us/step - loss: 0.5235 - accuracy: 0.7779\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 64us/step - loss: 0.5235 - accuracy: 0.7776\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5209 - accuracy: 0.7779\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5233 - accuracy: 0.7779\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 68us/step - loss: 0.5224 - accuracy: 0.7779 0s - loss: 0.523 - ETA: 0s - loss: 0.5232 - accuracy: 0. - ETA: 0s - loss: 0.5235 - ac\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 72us/step - loss: 0.5235 - accuracy: 0.7779\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 2s 75us/step - loss: 0.5241 - accuracy: 0.7779\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 75us/step - loss: 0.5767 - accuracy: 0.7670\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 72us/step - loss: 0.5154 - accuracy: 0.7795\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 75us/step - loss: 0.5133 - accuracy: 0.7794\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 66us/step - loss: 0.5157 - accuracy: 0.7791 0s - loss: - ETA: 0s - loss: 0.5159 - accura\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 72us/step - loss: 0.5178 - accuracy: 0.7796\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 76us/step - loss: 0.5173 - accuracy: 0.7796 0s -\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 70us/step - loss: 0.5190 - accuracy: 0.7796\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 93us/step - loss: 0.5168 - accuracy: 0.7794\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 61us/step - loss: 0.5177 - accuracy: 0.7796\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5189 - accuracy: 0.7794\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 74us/step - loss: 0.5343 - accuracy: 0.7755 0s - l\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 63us/step - loss: 0.5132 - accuracy: 0.7798\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 64us/step - loss: 0.5098 - accuracy: 0.7803\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 73us/step - loss: 0.5063 - accuracy: 0.7804\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 74us/step - loss: 0.5064 - accuracy: 0.7803 0s - loss: 0.5017 - ac - ETA: 0s - loss: 0\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 98us/step - loss: 0.5051 - accuracy: 0.7804\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 2s 76us/step - loss: 0.5061 - accuracy: 0.7803 0s - loss: 0.5070 - accura\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 76us/step - loss: 0.5059 - accuracy: 0.7803\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 2s 89us/step - loss: 0.5060 - accuracy: 0.7801\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 70us/step - loss: 0.5045 - accuracy: 0.7803 \n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 72us/step - loss: 0.5645 - accuracy: 0.7739\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5157 - accuracy: 0.7782 0s - loss: 0.5156 - accuracy: 0.77\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5129 - accuracy: 0.7784\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5109 - accuracy: 0.7784\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 58us/step - loss: 0.5097 - accuracy: 0.7784\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 55us/step - loss: 0.5078 - accuracy: 0.7784 0s - loss: 0\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5080 - accuracy: 0.7784\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 73us/step - loss: 0.5066 - accuracy: 0.7784 0s - loss: 0.5058 - accuracy: 0.\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 2s 85us/step - loss: 0.5090 - accuracy: 0.7783\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 2s 82us/step - loss: 0.5078 - accuracy: 0.7784\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 79us/step - loss: 0.6018 - accuracy: 0.7679\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 2s 96us/step - loss: 0.5225 - accuracy: 0.7774 0s - loss: 0.5268 \n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 2s 81us/step - loss: 0.5278 - accuracy: 0.7772\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 59us/step - loss: 0.5147 - accuracy: 0.7774 \n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5114 - accuracy: 0.7774\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5117 - accuracy: 0.7774\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5118 - accuracy: 0.7774\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 56us/step - loss: 0.5106 - accuracy: 0.7774\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5114 - accuracy: 0.7774\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5109 - accuracy: 0.7774\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 70us/step - loss: 0.5321 - accuracy: 0.7759\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 64us/step - loss: 0.5136 - accuracy: 0.7789\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5109 - accuracy: 0.7789\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5085 - accuracy: 0.7790\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5071 - accuracy: 0.7789\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 55us/step - loss: 0.5076 - accuracy: 0.7789 0s - loss: 0.5090 - accura - ETA: 0s - loss: 0.5075 - accuracy: 0.\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 57us/step - loss: 0.5067 - accuracy: 0.7790\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5071 - accuracy: 0.7790\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5068 - accuracy: 0.7787 0s - loss: 0.5057 - accu\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5061 - accuracy: 0.7791\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 56us/step - loss: 0.5780 - accuracy: 0.7685\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5209 - accuracy: 0.7795\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 65us/step - loss: 0.5144 - accuracy: 0.7794 0s - loss: 0.5142 - accuracy: 0.\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 58us/step - loss: 0.5138 - accuracy: 0.7795 0s - loss: 0.5196 - \n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 57us/step - loss: 0.5140 - accuracy: 0.7795\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5129 - accuracy: 0.7795\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5106 - accuracy: 0.7795 0s - loss: 0.504\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5126 - accuracy: 0.7793\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5097 - accuracy: 0.7795\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5099 - accuracy: 0.7795\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 58us/step - loss: 0.5596 - accuracy: 0.7679\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5120 - accuracy: 0.7799\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5096 - accuracy: 0.7798 0s - loss: 0.5041 - \n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5097 - accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 69us/step - loss: 0.5094 - accuracy: 0.7795\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 56us/step - loss: 0.5092 - accuracy: 0.7800\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5073 - accuracy: 0.7798\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 49us/step - loss: 0.5079 - accuracy: 0.7799\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5077 - accuracy: 0.7798\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5080 - accuracy: 0.7799 0s - loss: 0.5096 - accuracy: \n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 61us/step - loss: 0.5701 - accuracy: 0.7680\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5182 - accuracy: 0.7766\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 49us/step - loss: 0.5153 - accuracy: 0.7772\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 49us/step - loss: 0.5136 - accuracy: 0.7772\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5117 - accuracy: 0.7767\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5114 - accuracy: 0.7772\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5096 - accuracy: 0.7772\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5094 - accuracy: 0.7772\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 49us/step - loss: 0.5109 - accuracy: 0.7772\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5116 - accuracy: 0.7772\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 62us/step - loss: 0.5457 - accuracy: 0.7775\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5135 - accuracy: 0.7791\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5107 - accuracy: 0.7791\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5093 - accuracy: 0.7791\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 2s 96us/step - loss: 0.5121 - accuracy: 0.7791\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 2s 77us/step - loss: 0.5092 - accuracy: 0.7790 0s - loss: 0.5096 - accuracy: 0.77\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 55us/step - loss: 0.5090 - accuracy: 0.7791\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 2s 91us/step - loss: 0.5094 - accuracy: 0.7791 0s - loss: 0.5095 - accuracy: \n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 63us/step - loss: 0.5090 - accuracy: 0.7791\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5077 - accuracy: 0.7791\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 82us/step - loss: 0.7269 - accuracy: 0.7510\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 55us/step - loss: 0.5237 - accuracy: 0.7759\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5159 - accuracy: 0.7779\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5132 - accuracy: 0.7774\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5121 - accuracy: 0.7777\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5105 - accuracy: 0.7779\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5094 - accuracy: 0.7779\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 60us/step - loss: 0.5099 - accuracy: 0.7779\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 55us/step - loss: 0.5081 - accuracy: 0.7777\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 2s 89us/step - loss: 0.5098 - accuracy: 0.7776\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 2s 74us/step - loss: 0.5433 - accuracy: 0.7750 1s - los\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 69us/step - loss: 0.5160 - accuracy: 0.7795 0s - loss:\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5113 - accuracy: 0.7795 0s -\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5112 - accuracy: 0.7795\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5093 - accuracy: 0.7794 0s - loss: 0.507\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5083 - accuracy: 0.7794 0s - loss: 0.5074 - accura\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5069 - accuracy: 0.7794\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5074 - accuracy: 0.7793\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5064 - accuracy: 0.7796\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5073 - accuracy: 0.7796\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5670 - accuracy: 0.7717 0s - loss: 0.5776 - accura\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5168 - accuracy: 0.7802\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5122 - accuracy: 0.7803\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5114 - accuracy: 0.7803\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5101 - accuracy: 0.7803\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 47us/step - loss: 0.5094 - accuracy: 0.7803 0s - loss: 0\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 47us/step - loss: 0.5108 - accuracy: 0.7803\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5113 - accuracy: 0.7801\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5095 - accuracy: 0.7803\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5101 - accuracy: 0.7803\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5404 - accuracy: 0.7733\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 47us/step - loss: 0.5158 - accuracy: 0.7782\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5191 - accuracy: 0.7782\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5174 - accuracy: 0.7784\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 49us/step - loss: 0.5179 - accuracy: 0.7784\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5174 - accuracy: 0.7784\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5165 - accuracy: 0.7784\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5169 - accuracy: 0.7784\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5145 - accuracy: 0.7784 0s - loss: 0.5153 - accuracy\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5156 - accuracy: 0.7784\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 53us/step - loss: 0.5496 - accuracy: 0.7721\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5191 - accuracy: 0.7768\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5176 - accuracy: 0.7774\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5175 - accuracy: 0.7774\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5187 - accuracy: 0.7774\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 47us/step - loss: 0.5150 - accuracy: 0.7774\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5179 - accuracy: 0.7774\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5155 - accuracy: 0.7774\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5162 - accuracy: 0.7774\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5138 - accuracy: 0.7774\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 51us/step - loss: 0.5506 - accuracy: 0.7733\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5163 - accuracy: 0.7790\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5185 - accuracy: 0.7789\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5175 - accuracy: 0.7790\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5155 - accuracy: 0.7789\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5160 - accuracy: 0.7790\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5168 - accuracy: 0.7790\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 57us/step - loss: 0.5155 - accuracy: 0.7790 0s\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 47us/step - loss: 0.5143 - accuracy: 0.7790 0s - loss: 0\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 63us/step - loss: 0.5170 - accuracy: 0.7790\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5750 - accuracy: 0.7682\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5222 - accuracy: 0.7794\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5146 - accuracy: 0.7795\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5138 - accuracy: 0.7793\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5140 - accuracy: 0.7795\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5141 - accuracy: 0.7795\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5149 - accuracy: 0.7795\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5165 - accuracy: 0.7790\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5142 - accuracy: 0.7793 0s - loss: 0.515\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5157 - accuracy: 0.7794\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 49us/step - loss: 0.5539 - accuracy: 0.7726\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5147 - accuracy: 0.7799\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5107 - accuracy: 0.7797\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 52us/step - loss: 0.5100 - accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5098 - accuracy: 0.7799\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5094 - accuracy: 0.7799\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5086 - accuracy: 0.7799\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 43us/step - loss: 0.5105 - accuracy: 0.7799\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5100 - accuracy: 0.7797\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5115 - accuracy: 0.7798\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 49us/step - loss: 0.7430 - accuracy: 0.7482\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5209 - accuracy: 0.7770\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 44us/step - loss: 0.5175 - accuracy: 0.7772\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 47us/step - loss: 0.5155 - accuracy: 0.7769\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5142 - accuracy: 0.7772\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5146 - accuracy: 0.7772\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5143 - accuracy: 0.7771\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5158 - accuracy: 0.7772\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5147 - accuracy: 0.7772\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 42us/step - loss: 0.5142 - accuracy: 0.7772\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 66us/step - loss: 0.5615 - accuracy: 0.7706\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 57us/step - loss: 0.5186 - accuracy: 0.7791 0s - loss: 0.5236 - ac\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5154 - accuracy: 0.7790\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5146 - accuracy: 0.7790\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5117 - accuracy: 0.7790\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5100 - accuracy: 0.7790\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5101 - accuracy: 0.7790\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5096 - accuracy: 0.7790\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5102 - accuracy: 0.7791\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5092 - accuracy: 0.7791\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 54us/step - loss: 0.5982 - accuracy: 0.7676\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5172 - accuracy: 0.7775\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5140 - accuracy: 0.7780\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5135 - accuracy: 0.7779\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5125 - accuracy: 0.7778\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 47us/step - loss: 0.5117 - accuracy: 0.7779\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5121 - accuracy: 0.7779\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5117 - accuracy: 0.7779\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 50us/step - loss: 0.5112 - accuracy: 0.7779\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5115 - accuracy: 0.7778\n",
      "Epoch 1/10\n",
      "20250/20250 [==============================] - 1s 57us/step - loss: 0.6169 - accuracy: 0.7663\n",
      "Epoch 2/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5160 - accuracy: 0.7795\n",
      "Epoch 3/10\n",
      "20250/20250 [==============================] - 1s 48us/step - loss: 0.5157 - accuracy: 0.7795\n",
      "Epoch 4/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5165 - accuracy: 0.7795\n",
      "Epoch 5/10\n",
      "20250/20250 [==============================] - 1s 45us/step - loss: 0.5132 - accuracy: 0.7796\n",
      "Epoch 6/10\n",
      "20250/20250 [==============================] - 1s 58us/step - loss: 0.5116 - accuracy: 0.7796\n",
      "Epoch 7/10\n",
      "20250/20250 [==============================] - 1s 57us/step - loss: 0.5112 - accuracy: 0.7795\n",
      "Epoch 8/10\n",
      "20250/20250 [==============================] - 1s 47us/step - loss: 0.5110 - accuracy: 0.7795 0s - loss: 0\n",
      "Epoch 9/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5117 - accuracy: 0.7796 0s - loss: 0.5126 - accuracy\n",
      "Epoch 10/10\n",
      "20250/20250 [==============================] - 1s 46us/step - loss: 0.5114 - accuracy: 0.7795\n",
      "Epoch 1/10\n",
      "22500/22500 [==============================] - 2s 68us/step - loss: 0.6370 - accuracy: 0.7699\n",
      "Epoch 2/10\n",
      "22500/22500 [==============================] - 1s 64us/step - loss: 0.5167 - accuracy: 0.7788\n",
      "Epoch 3/10\n",
      "22500/22500 [==============================] - 2s 69us/step - loss: 0.5125 - accuracy: 0.7787\n",
      "Epoch 4/10\n",
      "22500/22500 [==============================] - 1s 65us/step - loss: 0.5094 - accuracy: 0.7788 0s - loss: 0.5080 - accu\n",
      "Epoch 5/10\n",
      "22500/22500 [==============================] - 1s 62us/step - loss: 0.5098 - accuracy: 0.7788\n",
      "Epoch 6/10\n",
      "22500/22500 [==============================] - 1s 59us/step - loss: 0.5083 - accuracy: 0.7788\n",
      "Epoch 7/10\n",
      "22500/22500 [==============================] - 2s 71us/step - loss: 0.5092 - accuracy: 0.7788\n",
      "Epoch 8/10\n",
      "22500/22500 [==============================] - 1s 65us/step - loss: 0.5093 - accuracy: 0.7787\n",
      "Epoch 9/10\n",
      "22500/22500 [==============================] - 1s 64us/step - loss: 0.5099 - accuracy: 0.7785\n",
      "Epoch 10/10\n",
      "22500/22500 [==============================] - 1s 67us/step - loss: 0.5089 - accuracy: 0.7786 0s - loss: 0.5089 - accuracy\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = grid_search.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = (y_pred_train > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = y_pred_train.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5048242591316333\n",
      "Precision Score : 0.5024333719582851\n",
      "Recall Score : 0.9960946473696302\n",
      "F1 Score : 0.6679503966725719\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics Train (data - cleanedcreditcard_2)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train)))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train)))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7789333333333334\n",
      "Precision Score : 0.6363636363636364\n",
      "Recall Score : 0.0014064697609001407\n",
      "F1 Score : 0.002806736166800321\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics Train (data - cleanedcreditcard_2)(without sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train)))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train)))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6096944635883299\n",
      "Precision Score : 0.5916682664618929\n",
      "Recall Score : 0.708017459223524\n",
      "F1 Score : 0.6446350135954821\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics Train (data - cleanedcreditcard_1)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_train,y_pred_train)))\n",
    "print('Precision Score : ' + str(precision_score(y_train,y_pred_train)))\n",
    "print('Recall Score : ' + str(recall_score(y_train,y_pred_train)))\n",
    "print('F1 Score : ' + str(f1_score(y_train,y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.5056283023202389\n",
      "Precision Score : 0.5028392629505157\n",
      "Recall Score : 0.9967838272455778\n",
      "F1 Score : 0.6684640271144663\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics Test (data - cleanedcreditcard_2)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7794666666666666\n",
      "Precision Score : 1.0\n",
      "Recall Score : 0.0030138637733574444\n",
      "F1 Score : 0.006009615384615385\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics Test (data - cleanedcreditcard_2) (without sampling)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6006202618883528\n",
      "Precision Score : 0.5847523219814241\n",
      "Recall Score : 0.6942338617045716\n",
      "F1 Score : 0.6348072681441025\n"
     ]
    }
   ],
   "source": [
    "# New Model Evaluation metrics Test (data - cleanedcreditcard_1)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.51      0.56      4353\n",
      "    positive       0.58      0.69      0.63      4353\n",
      "\n",
      "    accuracy                           0.60      8706\n",
      "   macro avg       0.60      0.60      0.60      8706\n",
      "weighted avg       0.60      0.60      0.60      8706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation for test (data - cleanedcreditcard_1)\n",
    "target_names = ['negative', 'positive']\n",
    "print(classification_report(y_test, y_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.01      0.03      4353\n",
      "    positive       0.50      1.00      0.67      4353\n",
      "\n",
      "    accuracy                           0.51      8706\n",
      "   macro avg       0.66      0.51      0.35      8706\n",
      "weighted avg       0.66      0.51      0.35      8706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation for test (data - cleanedcreditcard_2)\n",
    "target_names = ['negative', 'positive']\n",
    "print(classification_report(y_test, y_pred, target_names= target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
